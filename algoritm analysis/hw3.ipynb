{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From SAV to LOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__1.__ Измените функцию calc_logloss так, чтобы нули по возможности не попадали в np.log.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_logloss(y, y_pred):\n",
    "# при использовании сигмоиды  теоретически не может оказаться значения в y_pred значений равных 0 или 1 \n",
    "    eps = 1e-7\n",
    "    y_pred[y_pred ==0] = eps\n",
    "    y_pred[y_pred ==1] = 1 - eps\n",
    "\n",
    "    err = - np.mean(y * np.log(y_pred) + (1.0 - y) * np.log(1.0 - y_pred))\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1602343980014793"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0])\n",
    "y_pred = np.array([0.1, 0.7, 0.85, 0, 1., 0.67, 0.15, 0.25, 0.6, 0.4])\n",
    "calc_logloss(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "__2.__Подберите аргументы функции eval_model для логистической регрессии таким образом, чтобы log loss был минимальным.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 1, 3, 0, 5, 10, 1, 2],\n",
    "              [500, 700, 750, 600, 1450,\n",
    "               800, 1500, 2000, 450, 1000],\n",
    "              [1, 1, 2, 1, 2, \n",
    "               1, 3, 3, 1, 2]], dtype = np.float64)\n",
    "\n",
    "y = np.array([0, 0, 1, 0, 1, 0, 1, 0, 1, 1], dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_feat(X):\n",
    "    X_st = X.copy()\n",
    "    for i in range(1,X.shape[0]):\n",
    "        X_st[i, :] = (X_st[i, :] - X_st[i, :].mean())/X_st[i, :].std()\n",
    "    return X_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ],\n",
       "       [-0.57142857, -0.57142857, -0.21428571, -0.57142857,  0.14285714,\n",
       "        -0.92857143,  0.85714286,  2.64285714, -0.57142857, -0.21428571],\n",
       "       [-0.97958969, -0.56713087, -0.46401617, -0.77336028,  0.97958969,\n",
       "        -0.36090146,  1.08270439,  2.11385144, -1.08270439,  0.05155735],\n",
       "       [-0.89625816, -0.89625816,  0.38411064, -0.89625816,  0.38411064,\n",
       "        -0.89625816,  1.66447944,  1.66447944, -0.89625816,  0.38411064]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_st = std_feat(X)\n",
    "X_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1 / (1 + np.exp(-z))\n",
    "    return res\n",
    "def eval_model(X, y, iterations, alpha=1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    errs = []\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        errs.append(calc_logloss(y, y_pred))\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T))\n",
    "    if i % (iterations / 10) == 0:\n",
    "        print(i, W, errs[-2:])\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [ 145.0342788  -313.55463095 -433.6823138   873.17102269] [3.478551142892576e-06, 3.473347272444196e-06]\n"
     ]
    }
   ],
   "source": [
    "W = eval_model(X_st, y, iterations=1000, alpha=410)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 0.1 -0.00030999857 0.17982282336947347\n",
      "10000 1 -0.000142886631 0.07773202597709114\n",
      "10000 10 -8.1597477e-05 0.018809137625735647\n",
      "1997 100 -4.137409e-06 2.638735805269096e-05\n",
      "680 200 -4.823604e-06 0.0005715334302861754\n",
      "197 300 -2.96992e-07 9.31917491016752e-06\n",
      "269 400 -3.139803e-06 9.095656340140782e-06\n",
      "218 410 -2.450149e-06 7.378996504398123e-06\n",
      "206 500 -7.33069e-07 2.7651669771198545e-06\n",
      "402 600 -2.335559e-06 5.428449434778407e-06\n",
      "193 700 -1.935525e-06 3.309402781568888e-06\n"
     ]
    }
   ],
   "source": [
    "# Произведем вычисление зависимости количествоа итераций для сходимости по logloss в зависимости от выбираемого шага \n",
    "X1 = X_st.copy()\n",
    "steps = [0.1, 1, 10 ,100, 200, 300,400,410,500, 600, 700 ]\n",
    "N =[]\n",
    "ss = []\n",
    "eps = 1e-5 # определим точность сдля определения сходимости \n",
    "iterations = 10000 \n",
    "np.random.seed(42)\n",
    "W = np.random.randn(X1.shape[0])\n",
    "n = X1.shape[1]\n",
    "for alpha in steps:\n",
    "    W = np.random.randn(X1.shape[0])\n",
    "    errs = []\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X1)\n",
    "        y_pred = sigmoid(z)\n",
    "        errs.append(calc_logloss(y, y_pred))\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X1.T))\n",
    "        if (i > 100) and (abs(errs[-100]-errs[-1]) < eps):\n",
    "            N.append(i)\n",
    "            ss.append(alpha)\n",
    "            break\n",
    "        elif i == iterations:\n",
    "            N.append(i)\n",
    "            ss.append(alpha)\n",
    "            break\n",
    "    print(i, alpha, round(errs[-1]-errs[-50],12) , errs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1c3e896d978>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# зависимость количества итераций от шагов\n",
    "plt.scatter(ss,N, color='r') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вдно оптимальный вариант alpha для дальнейших операций  400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "__3.__ Создайте функцию calc_pred_proba, возвращающую предсказанную вероятность класса 1 (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred_proba).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [  59.86065924 -370.5462261  -210.42645761  546.36012062] [1.4425785675164577e-05, 1.4420243885472945e-05]\n"
     ]
    }
   ],
   "source": [
    "# Обучим модель\n",
    "W = eval_model(X_st, y, iterations=1000, alpha=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred_proba(W,X):\n",
    "    return sigmoid(np.dot(W, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.48010076e-006, 1.31277510e-043, 1.00000000e+000, 9.22332373e-025,\n",
       "       9.99976456e-001, 5.56038975e-005, 1.00000000e+000, 2.90573094e-198,\n",
       "       9.99941784e-001, 1.00000000e+000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba(W,X_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "__4.__Создайте функцию calc_pred, возвращающую предсказанный класс (на вход подаются W, который уже посчитан функцией eval_model и X, на выходе - массив y_pred).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(W,X,p = 0.5):\n",
    "    y = sigmoid(np.dot(W, X))\n",
    "    for i in range(len(y)):\n",
    "        if y[i] >= p:\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.]),\n",
       " array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = calc_pred(W,X_st)\n",
    "y_pred, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "__5.__Посчитайте Accuracy, матрицу ошибок, точность и полноту, а также F1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err_matrix(y,y_pred):\n",
    "    df = pd.DataFrame({\n",
    "    \"Y_true\": y,\n",
    "    \"Y_pred\": y_pred\n",
    "    })\n",
    "    M = np.zeros([2,2])\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            M[i,j] = df[(df['Y_true']==1-j) &(df['Y_pred'] ==1-i)].count()[0]\n",
    "    return(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 1. 0. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 0. 0. 0. 1. 1.]\n",
      "[[4. 2.]\n",
      " [1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# Проверим их\n",
    "y1 = np.array([1., 1., 1., 0., 1., 0., 0., 0., 1., 1.])\n",
    "print(y)\n",
    "print(y1)\n",
    "print(err_matrix(y,y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0.],\n",
       "       [0., 5.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вычислим матрицу ошибки по примеру\n",
    "M = err_matrix(y,y_pred)\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 1.0\n",
      "Error matrix = \n",
      "[[5. 0.]\n",
      " [0. 5.]]\n",
      "Precision = 1.0\n",
      "Recall = 1.0\n",
      "F1 Score = 1.0\n"
     ]
    }
   ],
   "source": [
    "Precision = M[0,0]/(M[0,0]+M[0,1])\n",
    "Recall = M[0,0]/(M[0,0]+M[1,0])\n",
    "print(f'Accuracy = {(M[0,0]+M[1,1])/M.sum()}')\n",
    "print(f'Error matrix = \\n{M}')\n",
    "print(f'Precision = {Precision}')\n",
    "print(f'Recall = {Recall}')\n",
    "print(f'F1 Score = {2*Precision*Recall/(Precision+Recall)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "__6.__Могла ли модель переобучиться? Почему? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, т.к. мы проводим обучение на тренировочных данных, и соотвесвенно у нас получается точное обучение для существующтих данных, что на другом массиве может оказать что выборка не соответсвует той выборке на которой мы проводим обучение. За счет этого и получается эффект переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "__7*.__ Создайте функции eval_model_l1 и eval_model_l2 с применением L1 и L2 регуляризаций соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_l2(X, y, iterations, alpha= 1, lambda_ = 1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    errs = []\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        errs.append(calc_logloss(y, y_pred))\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T)-2*lambda_*W)\n",
    "    if i % (iterations / 10) == 0:\n",
    "        print(i, W, errs[-2:])\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [ 1.59650098 -6.50673327 -0.56062723  8.74480686] [0.3233688580203328, 0.3234447150009953]\n"
     ]
    }
   ],
   "source": [
    "# Попробуем обучить систему со следующими парметрами\n",
    "W =eval_model_l2(X_st, y, iterations=1000, alpha=0.01 , lambda_ = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 1., 0., 1., 1., 1., 0., 0., 1.]),\n",
       " array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# результат схож но немного другой\n",
    "y_pred_l2 = calc_pred(W,X_st)\n",
    "y_pred_l2, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12198286, 0.09930049, 0.99865486, 0.11013103, 0.97001913,\n",
       "       0.50079857, 0.99995312, 0.09714152, 0.12831089, 0.99820485])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba(W,X_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_l1(X, y, iterations, alpha= 7, lambda_ = 1e-4):\n",
    "    np.random.seed(42)\n",
    "    W = np.random.randn(X.shape[0])\n",
    "    n = X.shape[1]\n",
    "    errs = []\n",
    "    for i in range(1, iterations+1):\n",
    "        z = np.dot(W, X)\n",
    "        y_pred = sigmoid(z)\n",
    "        errs.append(calc_logloss(y, y_pred))\n",
    "        W -= alpha * (1/n * np.dot((y_pred - y), X.T)-lambda_*np.sign(W))\n",
    "    if i % (iterations / 10) == 0:\n",
    "        print(i, W, errs[-2:])\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 [ 0.59643005 -2.28963431  0.56335132  2.43164934] [0.4377929565308422, 0.4377254820920764]\n"
     ]
    }
   ],
   "source": [
    "W = eval_model_l1(X_st, y, iterations=1000, alpha=0.01,lambda_ = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 1., 0., 1., 1., 1., 0., 0., 1.]),\n",
       " array([0., 0., 1., 0., 1., 0., 1., 0., 1., 1.]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_l1 = calc_pred(W,X_st)\n",
    "y_pred_l1, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30439703, 0.35569766, 0.85317011, 0.32953994, 0.85260935,\n",
       "       0.5841466 , 0.96412774, 0.4460916 , 0.29223869, 0.88596108])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_pred_proba(W,X_st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

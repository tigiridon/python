# -*- coding: utf-8 -*-
"""hw7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ayq3zX7j1KuDVrUpfBlWrlNpF2S40YF3
"""

#From SAV to LOVE

"""# HW7

### **Задание № 1.** Сделайте краткий обзор какой-нибудь научной работы посвященной тому или иному алгоритму для object detection, который не рассматривался на уроке. Проведите анализ: Чем отличается выбранная вами на рассмотрение архитектура нейронной сети от других архитектур? В чем плюсы и минусы данной архитектуры? Какие могут возникнуть трудности при применении данной архитектуры на практике? Запустите детектор (SSD или Faster R-CNN) из детекторы_7.ipynb для своего изображения (любое фотореалистичное) и постройте 3 объекта, 10 объектов, 100 объектов детектора.

### **Задание № 2** Ссылка на репозиторий с полным кодом для обучения ssd нейросети - https://github.com/sergeyveneckiy/ssd-tensorflow. Попробуйте улучшить точность ее работы и напишите отчет, что вы пробовали изменить в ее параметрах и как это отражалось на процессе обучения нейронной сети. Обратите внимание! Мин. сист. требования для запуска данного проекта - это минимум 8 Gb ОЗУ. Если у вас недостаточно мощности компьютера, то вы можете просто изучить содержимое исходного кода и датасета данного проекта.

### **Задание №1**

YOLO - совершенно новый подход к обнаружению объектов.
Предыдущие работы по обнаружению объектов перепрофилируют классификаторы для выполнения обнаружения. Вместо этого мы рассматриваем обнаружение объектов как проблему регрессии для пространственно-разделенных ограничивающих рамок и вероятности ассоциированного класса. Единая нейронная сеть предсказывает ограничивающие прямоугольники и вероятности классов непосредственно из полных изображений в одной оценке.
Поскольку все обнаружение пайплайна - это единая сеть, его можно оптимизировать от начала до конца непосредственно при обнаружении. Унифицированная архитектура работает очень быстро.
Базовая модель YOLO обрабатывает изображения в реальном времени на 45 кадрах в секунду. Уменьшенная версия сети Fast YOLO, обрабатывает поразительную скорость 155 кадров в секунду, в то время как по-прежнему достигается вдвое большее значение MAP, чем у других детекторов реального времени. По сравнению с современными системами обнаружения, YOLO делает больше ошибок локализации, но с меньшей вероятностью предсказывает ложные срабатывания на фоне. Наконец, YOLO учится очень общие представления объектов. Он превосходит другие методы обнаружения, включая DPM и R-CNN, при обобщении естественных изображений на другие области, такие как произведения искусства.
источник : https://arxiv.org/pdf/1506.02640.pdf

### **Задание №2**
"""

# Commented out IPython magic to ensure Python compatibility.

# Currently %tensorflow_version 2.x installs beta1, which doesn't work here.
# %tensorflow_version can likely be used after 2.0rc0  
#!pip install tf-nightly-gpu-2.0-preview
#!pip install tf-nightly-gpu-2.0-preview
from __future__ import absolute_import, division, print_function, unicode_literals

# Install TensorFlow

import tensorflow as tf

# For running inference on the TF-Hub module.
import tensorflow as tf

import tensorflow_hub as hub

# For downloading the image.
import matplotlib.pyplot as plt
import tempfile
from six.moves.urllib.request import urlopen
from six import BytesIO

# For drawing onto the image.
import numpy as np
from PIL import Image
from PIL import ImageColor
from PIL import ImageDraw
from PIL import ImageFont
from PIL import ImageOps

# For measuring the inference time.
import time
# %matplotlib inline

# Check available GPU devices.
print("The following GPU devices are available: %s" % tf.test.gpu_device_name())

from google.colab import files

import cv2 as cv

files.upload()

#Читаем картинку
im = cv.imread('/content/1840854.jpg')
    
# размеры изображения
newH = 200  #высота
newW = int(im.shape[1]*200/im.shape[0]) # ширина 
#сжатая картинка
im = cv.resize(im, (newW, newH)) 
#Выводим 

plt.imshow(im)
plt.show()

#Настройка модели
cv.setUseOptimized(True) #режим оптимизации
cv.setNumThreads(6)      #количество потоков

# Объект Selective Search Segmentation
sss = cv.ximgproc.segmentation.createSelectiveSearchSegmentation()

# запускаем с картинкой
sss.setBaseImage(im)
  
# Выбираем точный метод 
sss.switchToSelectiveSearchQuality()

# Делаем selective search segmentation 
rects = sss.process() 
#вернёт массив прямоугольников, гдевозможно что-то есть
print(rects.shape) #число найденых объектов

#Построим области

num_Rects = 150 #число выводимых region proposals (прямоугольников)

#создаем копию исходной картинки
im_ = im.copy()

for i, rect in enumerate(rects): 
  if (i < num_Rects): #пока не больше 
    # x,y - координаты левого верхнего угла; w, h - ширина и высота области
    x, y, w, h = rect
    # рисуем рамку      
    cv.rectangle(im_, (x, y), (x+w, y+h), (0, 255, 0), 1, cv.LINE_AA) 
  else: 
    break 

# Рисуем на экран
plt.figure(figsize=(16,5))
plt.imshow(im_) 
plt.show()

files.upload()

imf = cv.imread('/content/1840854.jpg')

#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml
face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')
#https://github.com/Itseez/opencv/blob/master/data/haarcascades/haarcascade_eye.xml
eye_cascade = cv.CascadeClassifier('haarcascade_eye.xml')


gray = cv.cvtColor(imf, cv.COLOR_RGB2GRAY)
faces = face_cascade.detectMultiScale(gray, 1.3, 5)


for (x,y,w,h) in faces:
     cv.rectangle(imf,(x,y),(x+w,y+h),(255,0,0),2)
     roi_gray = gray[y:y+h, x:x+w]
     roi_color = imf[y:y+h, x:x+w]

     eyes = eye_cascade.detectMultiScale(roi_gray)
     for (ex,ey,ew,eh) in eyes:
         cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)
plt.figure(figsize=(10,10))
plt.imshow(imf)      
plt.show()